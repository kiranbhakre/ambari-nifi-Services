<?xml version="1.0" encoding="UTF-8" standalone="yes"?><template><description>Combine data from RDBMS, weblog and Twitter</description><name>Single view demo</name><snippet><labels><id>ab30759f-b96a-40be-a9d3-c009d3a8ae08</id><parentGroupId>7c84501d-d10c-407c-b9f3-1d80e38fe36a</parentGroupId><position><x>1010.257315809931</x><y>80.08030258985933</y></position><height>150.0</height><label>Before running this processor run below to simulate weblogs for 10 (or more) users:


git clone https://github.com/abajwa-hw/single-view-demo.git 

./single-view-demo/createlog-psql.sh /tmp/data/DimCustomer.csv 10 &gt;&gt; /tmp/webtraffic.log</label><style><entry><key>font-size</key><value>12px</value></entry></style><width>150.0</width></labels><processGroups><id>0aa832d2-26b6-44c0-bf07-e999943e6975</id><parentGroupId>7c84501d-d10c-407c-b9f3-1d80e38fe36a</parentGroupId><position><x>990.0760416994694</x><y>152.95784513004716</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>7b8150dd-4967-430d-8218-1b012597eaec</id><parentGroupId>0aa832d2-26b6-44c0-bf07-e999943e6975</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><bends><x>451.99999893422216</x><y>342.0000013685168</y></bends><bends><x>451.99999893422216</x><y>392.0000013685168</y></bends><destination><groupId>0aa832d2-26b6-44c0-bf07-e999943e6975</groupId><id>d8fa2877-2f93-47b3-8e6b-75cb3c91600b</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>0aa832d2-26b6-44c0-bf07-e999943e6975</groupId><id>d8fa2877-2f93-47b3-8e6b-75cb3c91600b</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>2000e91c-bdd7-41f4-a997-cac20bf9820a</id><parentGroupId>0aa832d2-26b6-44c0-bf07-e999943e6975</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0aa832d2-26b6-44c0-bf07-e999943e6975</groupId><id>031ad4d3-05c4-4e3b-b41c-2e49968cd2fc</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>0aa832d2-26b6-44c0-bf07-e999943e6975</groupId><id>926f20cd-a086-4b64-83ca-f4f09c40d8ab</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>0cf2614f-541d-4017-85b5-fc6e81b668d9</id><parentGroupId>0aa832d2-26b6-44c0-bf07-e999943e6975</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>0aa832d2-26b6-44c0-bf07-e999943e6975</groupId><id>d8fa2877-2f93-47b3-8e6b-75cb3c91600b</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>0aa832d2-26b6-44c0-bf07-e999943e6975</groupId><id>031ad4d3-05c4-4e3b-b41c-2e49968cd2fc</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><processors><id>926f20cd-a086-4b64-83ca-f4f09c40d8ab</id><parentGroupId>0aa832d2-26b6-44c0-bf07-e999943e6975</parentGroupId><position><x>39.999998934222134</x><y>17.00000136851679</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>File to Tail</key><value><description>Fully-qualified filename of the file that should be tailed</description><displayName>File to Tail</displayName><dynamic>false</dynamic><name>File to Tail</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Rolling Filename Pattern</key><value><description>If the file to tail &quot;rolls over&quot; as would be the case with log files, this filename pattern will be used to identify files that have rolled over so that if NiFi is restarted, and the file has rolled over, it will be able to pick up where it left off. This pattern supports wildcard characters * and ? and will assume that the files that have rolled over live in the same directory as the file being tailed.</description><displayName>Rolling Filename Pattern</displayName><dynamic>false</dynamic><name>Rolling Filename Pattern</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>State File</key><value><defaultValue>./conf/state/926f20cd-a086-4b64-83ca-f4f09c40d8ab</defaultValue><description>Specifies the file that should be used for storing state about what data has been ingested so that upon restart NiFi can resume from where it left off</description><displayName>State File</displayName><dynamic>false</dynamic><name>State File</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Initial Start Position</key><value><allowableValues><description>Start with the oldest data that matches the Rolling Filename Pattern and then begin reading from the File to Tail</description><displayName>Beginning of Time</displayName><value>Beginning of Time</value></allowableValues><allowableValues><description>Start with the beginning of the File to Tail. Do not ingest any data that has already been rolled over</description><displayName>Beginning of File</displayName><value>Beginning of File</value></allowableValues><allowableValues><description>Start with the data at the end of the File to Tail. Do not ingest any data thas has already been rolled over or any data in the File to Tail that has already been written.</description><displayName>Current Time</displayName><value>Current Time</value></allowableValues><defaultValue>Beginning of File</defaultValue><description>When the Processor first begins to tail data, this property specifies where the Processor should begin reading data. Once data has been ingested from the file, the Processor will continue from the last point from which it has received data.</description><displayName>Initial Start Position</displayName><dynamic>false</dynamic><name>Initial Start Position</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>File to Tail</key><value>/tmp/webtraffic.log</value></entry><entry><key>Rolling Filename Pattern</key></entry><entry><key>State File</key></entry><entry><key>Initial Start Position</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>TailFile</name><relationships><autoTerminate>false</autoTerminate><description>All FlowFiles are routed to this Relationship.</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>false</supportsParallelProcessing><type>org.apache.nifi.processors.standard.TailFile</type></processors><processors><id>d8fa2877-2f93-47b3-8e6b-75cb3c91600b</id><parentGroupId>0aa832d2-26b6-44c0-bf07-e999943e6975</parentGroupId><position><x>42.999998934222134</x><y>317.0000013685168</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key></entry><entry><key>Directory</key><value>/tmp/weblog_staging</value></entry><entry><key>Conflict Resolution Strategy</key></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>031ad4d3-05c4-4e3b-b41c-2e49968cd2fc</id><parentGroupId>0aa832d2-26b6-44c0-bf07-e999943e6975</parentGroupId><position><x>39.999998934222134</x><y>165.0000013685168</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Merge Strategy</key></entry><entry><key>Merge Format</key></entry><entry><key>Attribute Strategy</key></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Minimum Number of Entries</key><value>10</value></entry><entry><key>Maximum Number of Entries</key></entry><entry><key>Minimum Group Size</key></entry><entry><key>Maximum Group Size</key></entry><entry><key>Max Bin Age</key></entry><entry><key>Maximum number of Bins</key></entry><entry><key>Delimiter Strategy</key></entry><entry><key>Header File</key></entry><entry><key>Footer File</key></entry><entry><key>Demarcator File</key></entry><entry><key>Compression Level</key></entry><entry><key>Keep Path</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent</name><relationships><autoTerminate>true</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>0</inputPortCount><invalidCount>0</invalidCount><name>Push weblogs to HDFS</name><outputPortCount>0</outputPortCount><parent><id>7c84501d-d10c-407c-b9f3-1d80e38fe36a</id><name>NiFi Flow</name></parent><runningCount>0</runningCount><stoppedCount>3</stoppedCount></processGroups><processGroups><id>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</id><parentGroupId>7c84501d-d10c-407c-b9f3-1d80e38fe36a</parentGroupId><position><x>533.7505770686353</x><y>160.8061961184259</y></position><activeRemotePortCount>0</activeRemotePortCount><comments></comments><contents><connections><id>3c9024a1-4c94-4f1d-b004-4c25f5b2f922</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><bends><x>1375.1673094034688</x><y>504.1860631043438</y></bends><bends><x>1375.1673094034688</x><y>554.1860631043438</y></bends><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>3af7b6de-13bd-40c7-a177-223107fe329b</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>failure</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>3af7b6de-13bd-40c7-a177-223107fe329b</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>8133869f-b343-4163-8773-3e3c661d246d</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>765aa19b-a0b6-49a5-b06f-eb924b52459c</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>tweet</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>5f8f1ccf-8128-4397-9347-2a03441a4faf</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>fca80621-6a4b-413f-b889-0c21236cde24</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>47bb8af9-9b29-43d9-9637-7da6bef81e09</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>tweet</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>5f8f1ccf-8128-4397-9347-2a03441a4faf</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>78aa7bf9-239f-4946-ba39-6710213b11f6</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>0a567555-bba9-4314-ab47-66d5b7b5e767</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>e990fd8f-ee06-44e3-a37e-9fabf0024908</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>469dfaf8-37e1-4432-81c5-22cccd767985</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>982e1911-6be4-449b-b7ad-60da242ee355</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>e1f88669-cde3-4f4c-84a4-a03205df38a0</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>e632e2bc-4f82-496b-97d3-c00cae0a8931</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>3af7b6de-13bd-40c7-a177-223107fe329b</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>merged</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>e990fd8f-ee06-44e3-a37e-9fabf0024908</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>830f298b-2afe-4b25-a03e-af1d996cc78e</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>e990fd8f-ee06-44e3-a37e-9fabf0024908</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>success</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>47bb8af9-9b29-43d9-9637-7da6bef81e09</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><connections><id>62c39636-ef2a-4796-84ee-5d1fa07b9996</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><backPressureDataSizeThreshold>0 MB</backPressureDataSizeThreshold><backPressureObjectThreshold>0</backPressureObjectThreshold><destination><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>5f8f1ccf-8128-4397-9347-2a03441a4faf</id><type>PROCESSOR</type></destination><flowFileExpiration>0 sec</flowFileExpiration><labelIndex>1</labelIndex><name></name><selectedRelationships>matched</selectedRelationships><source><groupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</groupId><id>982e1911-6be4-449b-b7ad-60da242ee355</id><type>PROCESSOR</type></source><zIndex>0</zIndex></connections><processors><id>0a567555-bba9-4314-ab47-66d5b7b5e767</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>459.41607100345675</x><y>468.6240270576958</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Directory</key><value><description>The directory to which files should be written. You may use expression language such as /aa/bb/${path}</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Create Missing Directories</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>true</defaultValue><description>If true, then missing destination directories will be created. If false, flowfiles are penalized and sent to failure.</description><displayName>Create Missing Directories</displayName><dynamic>false</dynamic><name>Create Missing Directories</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum File Count</key><value><description>Specifies the maximum number of files that can exist in the output directory</description><displayName>Maximum File Count</displayName><dynamic>false</dynamic><name>Maximum File Count</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Last Modified Time</key><value><description>Sets the lastModifiedTime on the output file to the value of this attribute.  Format must be yyyy-MM-dd'T'HH:mm:ssZ.  You may also use expression language such as ${file.lastModifiedTime}.</description><displayName>Last Modified Time</displayName><dynamic>false</dynamic><name>Last Modified Time</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Permissions</key><value><description>Sets the permissions on the output file to the value of this attribute.  Format must be either UNIX rwxrwxrwx with a - in place of denied permissions (e.g. rw-r--r--) or an octal number (e.g. 644).  You may also use expression language such as ${file.permissions}.</description><displayName>Permissions</displayName><dynamic>false</dynamic><name>Permissions</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Owner</key><value><description>Sets the owner on the output file to the value of this attribute.  You may also use expression language such as ${file.owner}.</description><displayName>Owner</displayName><dynamic>false</dynamic><name>Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Group</key><value><description>Sets the group on the output file to the value of this attribute.  You may also use expression language such as ${file.group}.</description><displayName>Group</displayName><dynamic>false</dynamic><name>Group</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Directory</key><value>/tmp/tweets</value></entry><entry><key>Conflict Resolution Strategy</key><value>fail</value></entry><entry><key>Create Missing Directories</key><value>true</value></entry><entry><key>Maximum File Count</key></entry><entry><key>Last Modified Time</key></entry><entry><key>Permissions</key></entry><entry><key>Owner</key></entry><entry><key>Group</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutFile</name><relationships><autoTerminate>true</autoTerminate><description>Files that could not be written to the output directory for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to the output directory are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.PutFile</type></processors><processors><id>5f8f1ccf-8128-4397-9347-2a03441a4faf</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>-101.12229263071927</x><y>415.77229159831415</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>2</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Routing Strategy</key><value><allowableValues><description>A copy of the FlowFile will be routed to each relationship whose corresponding expression evaluates to 'true'</description><displayName>Route to Property name</displayName><value>Route to Property name</value></allowableValues><allowableValues><description>Requires that all user-defined expressions evaluate to 'true' for the FlowFile to be considered a match</description><displayName>Route to 'matched' if all match</displayName><value>Route to 'match' if all match</value></allowableValues><allowableValues><description>Requires that at least one user-defined expression evaluate to 'true' for hte FlowFile to be considered a match</description><displayName>Route to 'matched' if any matches</displayName><value>Route to 'match' if any matches</value></allowableValues><defaultValue>Route to Property name</defaultValue><description>Specifies how to determine which relationship to use when evaluating the Expression Language</description><displayName>Routing Strategy</displayName><dynamic>false</dynamic><name>Routing Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>tweet</key><value><description></description><displayName>tweet</displayName><dynamic>true</dynamic><name>tweet</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Routing Strategy</key><value>Route to Property name</value></entry><entry><key>tweet</key><value>${twitter.msg:isEmpty():not()}</value></entry></properties><runDurationMillis>25</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Find only Tweets</name><relationships><autoTerminate>false</autoTerminate><description></description><name>tweet</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that do not match any user-define expression will be routed here</description><name>unmatched</name></relationships><state>RUNNING</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.RouteOnAttribute</type></processors><processors><id>47bb8af9-9b29-43d9-9637-7da6bef81e09</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>347.4908657243287</x><y>331.2840828508703</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Regular Expression</key><value><defaultValue>(?s:^.*$)</defaultValue><description>The Search Value to search for in the FlowFile content. Only used for 'Literal Replace' and 'Regex Replace' matching strategies</description><displayName>Search Value</displayName><dynamic>false</dynamic><name>Regular Expression</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Replacement Value</key><value><defaultValue>$1</defaultValue><description>The value to insert using the 'Replacement Strategy'. Using &quot;Regex Replace&quot; back-references to Regular Expression capturing groups are supported, but back-references that reference capturing groups that do not exist in the regular expression will be treated as literal value. Back References may also be referenced using the Expression Language, as '$1', '$2', etc. The single-tick marks MUST be included, as these variables are not &quot;Standard&quot; attribute names (attribute names must be quoted unless they contain only numbers, letters, and _).</description><displayName>Replacement Value</displayName><dynamic>false</dynamic><name>Replacement Value</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Character Set</key><value><defaultValue>UTF-8</defaultValue><description>The Character Set in which the file is encoded</description><displayName>Character Set</displayName><dynamic>false</dynamic><name>Character Set</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Buffer Size</key><value><defaultValue>1 MB</defaultValue><description>Specifies the maximum amount of data to buffer (per file or per line, depending on the Evaluation Mode) in order to apply the replacement. If 'Entire Text' (in Evaluation Mode) is selected and the FlowFile is larger than this value, the FlowFile will be routed to 'failure'. In 'Line-by-Line' Mode, if a single line is larger than this value, the FlowFile will be routed to 'failure'. A default value of 1 MB is provided, primarily for 'Entire Text' mode. In 'Line-by-Line' Mode, a value such as 8 KB or 16 KB is suggested. This value is ignored if the &lt;Replacement Strategy&gt; property is set to one of: Append, Prepend, Always Replace</description><displayName>Maximum Buffer Size</displayName><dynamic>false</dynamic><name>Maximum Buffer Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replacement Strategy</key><value><allowableValues><description>Insert the Replacement Value at the beginning of the FlowFile or the beginning of each line (depending on the Evaluation Mode). For &quot;Line-by-Line&quot; Evaluation Mode, the value will be prepended to each line. For &quot;Entire Text&quot; evaluation mode, the value will be prepended to the entire text.</description><displayName>Prepend</displayName><value>Prepend</value></allowableValues><allowableValues><description>Insert the Replacement Value at the end of the FlowFile or the end of each line (depending on the Evluation Mode). For &quot;Line-by-Line&quot; Evaluation Mode, the value will be appended to each line. For &quot;Entire Text&quot; evaluation mode, the value will be appended to the entire text.</description><displayName>Append</displayName><value>Append</value></allowableValues><allowableValues><description>Interpret the Search Value as a Regular Expression and replace all matches with the Replacement Value. The Replacement Value may reference Capturing Groups used in the Search Value by using a dollar-sign followed by the Capturing Group number, such as $1 or $2. If the Search Value is set to .* then everything is replaced without even evaluating the Regular Expression.</description><displayName>Regex Replace</displayName><value>Regex Replace</value></allowableValues><allowableValues><description>Search for all instances of the Search Value and replace the matches with the Replacement Value.</description><displayName>Literal Replace</displayName><value>Literal Replace</value></allowableValues><allowableValues><description>Always replaces the entire line or the entire contents of the FlowFile (depending on the value of the &lt;Evaluation Mode&gt; property) and does not bother searching for any value. When this strategy is chosen, the &lt;Search Value&gt; property is ignored.</description><displayName>Always Replace</displayName><value>Always Replace</value></allowableValues><defaultValue>Regex Replace</defaultValue><description>The strategy for how and what to replace within the FlowFile's text content.</description><displayName>Replacement Strategy</displayName><dynamic>false</dynamic><name>Replacement Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Evaluation Mode</key><value><allowableValues><displayName>Line-by-Line</displayName><value>Line-by-Line</value></allowableValues><allowableValues><displayName>Entire text</displayName><value>Entire text</value></allowableValues><defaultValue>Entire text</defaultValue><description>Run the 'Replacement Strategy' against each line separately (Line-by-Line) or buffer the entire file into memory (Entire Text) and run against that.</description><displayName>Evaluation Mode</displayName><dynamic>false</dynamic><name>Evaluation Mode</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Regular Expression</key><value>(?s:^(.*)$)</value></entry><entry><key>Replacement Value</key><value>${twitter.tweet_id}|${twitter.unixtime}|${twitter.time}|${twitter.handle}|${twitter.msg:replace('$',''):replace('\n','')}|$1</value></entry><entry><key>Character Set</key><value>UTF-8</value></entry><entry><key>Maximum Buffer Size</key><value>1 MB</value></entry><entry><key>Replacement Strategy</key></entry><entry><key>Evaluation Mode</key><value>Entire text</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>ReplaceText</name><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that could not be updated are routed to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles that have been successfully processed are routed to this relationship. This includes both FlowFiles that had text replaced and those that did not.</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.ReplaceText</type></processors><processors><id>e1f88669-cde3-4f4c-84a4-a03205df38a0</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>-81.98087417368802</x><y>-58.30794483662237</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Twitter Endpoint</key><value><allowableValues><description>The endpoint that provides public data, aka a 'garden hose'</description><displayName>Sample Endpoint</displayName><value>Sample Endpoint</value></allowableValues><allowableValues><description>The endpoint that provides access to all tweets</description><displayName>Firehose Endpoint</displayName><value>Firehose Endpoint</value></allowableValues><allowableValues><description>Endpoint that allows the stream to be filtered by specific terms or User IDs</description><displayName>Filter Endpoint</displayName><value>Filter Endpoint</value></allowableValues><defaultValue>Sample Endpoint</defaultValue><description>Specifies which endpoint data should be pulled from</description><displayName>Twitter Endpoint</displayName><dynamic>false</dynamic><name>Twitter Endpoint</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Consumer Key</key><value><description>The Consumer Key provided by Twitter</description><displayName>Consumer Key</displayName><dynamic>false</dynamic><name>Consumer Key</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Consumer Secret</key><value><description>The Consumer Secret provided by Twitter</description><displayName>Consumer Secret</displayName><dynamic>false</dynamic><name>Consumer Secret</name><required>true</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Access Token</key><value><description>The Access Token provided by Twitter</description><displayName>Access Token</displayName><dynamic>false</dynamic><name>Access Token</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Access Token Secret</key><value><description>The Access Token Secret provided by Twitter</description><displayName>Access Token Secret</displayName><dynamic>false</dynamic><name>Access Token Secret</name><required>true</required><sensitive>true</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Languages</key><value><description>A comma-separated list of languages for which tweets should be fetched</description><displayName>Languages</displayName><dynamic>false</dynamic><name>Languages</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Terms to Filter On</key><value><description>A comma-separated list of terms to filter on. Ignored unless Endpoint is set to 'Filter Endpoint'. The filter works such that if any term matches, the status update will be retrieved; multiple terms separated by a space function as an 'AND'. I.e., 'it was, hello' will retrieve status updates that have either 'hello' or both 'it' AND 'was'</description><displayName>Terms to Filter On</displayName><dynamic>false</dynamic><name>Terms to Filter On</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IDs to Follow</key><value><description>A comma-separated list of Twitter User ID's to follow. Ignored unless Endpoint is set to 'Filter Endpoint'.</description><displayName>IDs to Follow</displayName><dynamic>false</dynamic><name>IDs to Follow</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Locations to Filter On</key><value><description>A comma-separated list of coordinates specifying one or more bounding boxes to filter on.Each bounding box is specified by a pair of coordinates in the format: swLon,swLat,neLon,neLat. Multiple bounding boxes can be specified as such: swLon1,swLat1,neLon1,neLat1,swLon2,swLat2,neLon2,neLat2.Ignored unless Endpoint is set to 'Filter Endpoint'.</description><displayName>Locations to Filter On</displayName><dynamic>false</dynamic><name>Locations to Filter On</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Twitter Endpoint</key><value>Filter Endpoint</value></entry><entry><key>Consumer Key</key><value>g28NxesU1Vpk12IBXCnIWs2Ur</value></entry><entry><key>Consumer Secret</key></entry><entry><key>Access Token</key><value>2885109412-UDQfXEUV2cQTYqCIbnsU7JtYqOaAksJCi6gbMgS</value></entry><entry><key>Access Token Secret</key></entry><entry><key>Languages</key></entry><entry><key>Terms to Filter On</key><value>GALAXYNOTE5,iPadPro,GalaxyS6,iPhone6S,SurfacePro4,VizioMseries,AppleTV,GoogleNexus6P,LGV10,iPhone6SPlus,GalaxyS6Edge,BlackBerryPriv,VizioEseries,SurfaceBook,GoogleNexus5X,GalaxyS5,MotorolaDroidTurbo2,AppleTV,FitbitChargeHR,NinjaCoffeeBar,iPhone6,Roku3,GalaxyTabS2,GalaxyNote4,iPadMini4,GearS2,iPhone6Plus,Roku2,iPadAir2,BoseQuietComfort25,LGG4,GalaxyS4,UNJS8500series,GalaxyS6Edge+,SimpliSafeHomeSecurity,GalaxyGrandPrime,AsusChromebit,LGEF9500series,Roku4,BeatsStudioWirelessHeadphones,LGG3,BoseSoundLinkMiniII,iPadMini2,BeatsPowerbeats2Wireless,NikonD3300,AmazonEcho,UEBoom2,NestCam,XboxOne,AmazonKindlePaperwhite,YamahaYAS203,GoogleNexus6,HTCOneM9,MacBookProRetina,MacBook,Nest,iPadAir2,LenovoYoga900,GoProHero3,LGGStylo,UNJU7100series,GearVR,Dysonv6,GalaxyS6Active,TiVoBolt,GalaxyTabA8.0,iPhone5S,RokuTV,GoogleNexus9,ChromecastAudio,SonyAlpha6000,JBLFlip3,LenovoYoga314,JawboneUp2,AppleCarPlay,GoProHero4Silver,HPSpectrex360,SonyXperiaZ5Premium,NetgearArloSmartHomeSecurity,MacBookAir,BoseSoundLinkBluetoothSpeakerIII,GalaxyCorePrime,Lumia950,SennheiserHD598,BeatsSolo2,VizioSB4051,SurfacePro3,HPStream11,SonyXperiaZ5,SennheiserMomentum2.0,SSD850Evo,iPhone5,AppleWatch</value></entry><entry><key>IDs to Follow</key></entry><entry><key>Locations to Filter On</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Grab Garden Hose</name><relationships><autoTerminate>false</autoTerminate><description>All status updates will be routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.twitter.GetTwitter</type></processors><processors><id>e990fd8f-ee06-44e3-a37e-9fabf0024908</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>890.901616061057</x><y>285.4346310401422</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Merge Strategy</key><value><allowableValues><description>Generates 'bins' of FlowFiles and fills each bin as full as possible. FlowFiles are placed into a bin based on their size and optionally their attributes (if the &lt;Correlation Attribute&gt; property is set)</description><displayName>Bin-Packing Algorithm</displayName><value>Bin-Packing Algorithm</value></allowableValues><allowableValues><description>Combines fragments that are associated by attributes back into a single cohesive FlowFile. If using this strategy, all FlowFiles must have the attributes &lt;fragment.identifier&gt;, &lt;fragment.count&gt;, and &lt;fragment.index&gt; or alternatively (for backward compatibility purposes) &lt;segment.identifier&gt;, &lt;segment.count&gt;, and &lt;segment.index&gt;. All FlowFiles with the same value for &quot;fragment.identifier&quot; will be grouped together. All FlowFiles in this group must have the same value for the &quot;fragment.count&quot; attribute. All FlowFiles in this group must have a unique value for the &quot;fragment.index&quot; attribute between 0 and the value of the &quot;fragment.count&quot; attribute.</description><displayName>Defragment</displayName><value>Defragment</value></allowableValues><defaultValue>Bin-Packing Algorithm</defaultValue><description>Specifies the algorithm used to merge content. The 'Defragment' algorithm combines fragments that are associated by attributes back into a single cohesive FlowFile. The 'Bin-Packing Algorithm' generates a FlowFile populated by arbitrarily chosen FlowFiles</description><displayName>Merge Strategy</displayName><dynamic>false</dynamic><name>Merge Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Merge Format</key><value><allowableValues><description>A bin of FlowFiles will be combined into a single TAR file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the TAR file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the TAR file. If a FlowFile has an attribute named &lt;tar.permissions&gt; that is 3 characters, each between 0-7, that attribute will be used as the TAR entry's 'mode'.</description><displayName>TAR</displayName><value>TAR</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single ZIP file. The FlowFiles' &lt;path&gt; attribute will be used to create a directory in the ZIP file if the &lt;Keep Paths&gt; property is set to true; otherwise, all FlowFiles will be added at the root of the ZIP file. The &lt;Compression Level&gt; property indicates the ZIP compression to use.</description><displayName>ZIP</displayName><value>ZIP</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 3 FlowFile Stream</description><displayName>FlowFile Stream, v3</displayName><value>FlowFile Stream, v3</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 2 FlowFile Stream</description><displayName>FlowFile Stream, v2</displayName><value>FlowFile Stream, v2</value></allowableValues><allowableValues><description>A bin of FlowFiles will be combined into a single Version 1 FlowFile Package</description><displayName>FlowFile Tar, v1</displayName><value>FlowFile Tar, v1</value></allowableValues><allowableValues><description>The contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Binary Concatenation</displayName><value>Binary Concatenation</value></allowableValues><allowableValues><description>The Avro contents of all FlowFiles will be concatenated together into a single FlowFile</description><displayName>Avro</displayName><value>Avro</value></allowableValues><defaultValue>Binary Concatenation</defaultValue><description>Determines the format that will be used to merge the content.</description><displayName>Merge Format</displayName><dynamic>false</dynamic><name>Merge Format</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Attribute Strategy</key><value><allowableValues><displayName>Keep Only Common Attributes</displayName><value>Keep Only Common Attributes</value></allowableValues><allowableValues><displayName>Keep All Unique Attributes</displayName><value>Keep All Unique Attributes</value></allowableValues><defaultValue>Keep Only Common Attributes</defaultValue><description>Determines which FlowFile attributes should be added to the bundle. If 'Keep All Unique Attributes' is selected, any attribute on any FlowFile that gets bundled will be kept unless its value conflicts with the value from another FlowFile. If 'Keep Only Common Attributes' is selected, only the attributes that exist on all FlowFiles in the bundle, with the same value, will be preserved.</description><displayName>Attribute Strategy</displayName><dynamic>false</dynamic><name>Attribute Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Correlation Attribute Name</key><value><description>If specified, like FlowFiles will be binned together, where 'like FlowFiles' means FlowFiles that have the same value for this Attribute. If not specified, FlowFiles are bundled by the order in which they are pulled from the queue.</description><displayName>Correlation Attribute Name</displayName><dynamic>false</dynamic><name>Correlation Attribute Name</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Number of Entries</key><value><defaultValue>1</defaultValue><description>The minimum number of files to include in a bundle</description><displayName>Minimum Number of Entries</displayName><dynamic>false</dynamic><name>Minimum Number of Entries</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Number of Entries</key><value><description>The maximum number of files to include in a bundle. If not specified, there is no maximum.</description><displayName>Maximum Number of Entries</displayName><dynamic>false</dynamic><name>Maximum Number of Entries</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Minimum Group Size</key><value><defaultValue>0 B</defaultValue><description>The minimum size of for the bundle</description><displayName>Minimum Group Size</displayName><dynamic>false</dynamic><name>Minimum Group Size</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum Group Size</key><value><description>The maximum size for the bundle. If not specified, there is no maximum.</description><displayName>Maximum Group Size</displayName><dynamic>false</dynamic><name>Maximum Group Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Max Bin Age</key><value><description>The maximum age of a Bin that will trigger a Bin to be complete. Expected format is &lt;duration&gt; &lt;time unit&gt; where &lt;duration&gt; is a positive integer and time unit is one of seconds, minutes, hours</description><displayName>Max Bin Age</displayName><dynamic>false</dynamic><name>Max Bin Age</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Maximum number of Bins</key><value><defaultValue>100</defaultValue><description>Specifies the maximum number of bins that can be held in memory at any one time</description><displayName>Maximum number of Bins</displayName><dynamic>false</dynamic><name>Maximum number of Bins</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Delimiter Strategy</key><value><allowableValues><description>The values of Header, Footer, and Demarcator will be retrieved from the contents of a file</description><displayName>Filename</displayName><value>Filename</value></allowableValues><allowableValues><description>The values of Header, Footer, and Demarcator will be specified as property values</description><displayName>Text</displayName><value>Text</value></allowableValues><defaultValue>Filename</defaultValue><description>Determines if Header, Footer, and Demarcator should point to files containing the respective content, or if the values of the properties should be used as the content.</description><displayName>Delimiter Strategy</displayName><dynamic>false</dynamic><name>Delimiter Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Header File</key><value><description>Filename specifying the header to use. If not specified, no header is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Header</displayName><dynamic>false</dynamic><name>Header File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Footer File</key><value><description>Filename specifying the footer to use. If not specified, no footer is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Footer</displayName><dynamic>false</dynamic><name>Footer File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Demarcator File</key><value><description>Filename specifying the demarcator to use. If not specified, no demarcator is supplied. This property is valid only when using the binary-concatenation merge strategy; otherwise, it is ignored.</description><displayName>Demarcator</displayName><dynamic>false</dynamic><name>Demarcator File</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Compression Level</key><value><allowableValues><displayName>0</displayName><value>0</value></allowableValues><allowableValues><displayName>1</displayName><value>1</value></allowableValues><allowableValues><displayName>2</displayName><value>2</value></allowableValues><allowableValues><displayName>3</displayName><value>3</value></allowableValues><allowableValues><displayName>4</displayName><value>4</value></allowableValues><allowableValues><displayName>5</displayName><value>5</value></allowableValues><allowableValues><displayName>6</displayName><value>6</value></allowableValues><allowableValues><displayName>7</displayName><value>7</value></allowableValues><allowableValues><displayName>8</displayName><value>8</value></allowableValues><allowableValues><displayName>9</displayName><value>9</value></allowableValues><defaultValue>1</defaultValue><description>Specifies the compression level to use when using the Zip Merge Format; if not using the Zip Merge Format, this value is ignored</description><displayName>Compression Level</displayName><dynamic>false</dynamic><name>Compression Level</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Keep Path</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If using the Zip or Tar Merge Format, specifies whether or not the FlowFiles' paths should be included in their entry names; if using other merge strategy, this value is ignored</description><displayName>Keep Path</displayName><dynamic>false</dynamic><name>Keep Path</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Merge Strategy</key><value>Bin-Packing Algorithm</value></entry><entry><key>Merge Format</key><value>Binary Concatenation</value></entry><entry><key>Attribute Strategy</key><value>Keep Only Common Attributes</value></entry><entry><key>Correlation Attribute Name</key></entry><entry><key>Minimum Number of Entries</key><value>20</value></entry><entry><key>Maximum Number of Entries</key><value>1000</value></entry><entry><key>Minimum Group Size</key><value>0 B</value></entry><entry><key>Maximum Group Size</key></entry><entry><key>Max Bin Age</key><value>120 seconds</value></entry><entry><key>Maximum number of Bins</key><value>100</value></entry><entry><key>Delimiter Strategy</key><value>Filename</value></entry><entry><key>Header File</key></entry><entry><key>Footer File</key></entry><entry><key>Demarcator File</key></entry><entry><key>Compression Level</key><value>1</value></entry><entry><key>Keep Path</key><value>false</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>MergeContent</name><relationships><autoTerminate>true</autoTerminate><description>If the bundle cannot be created, all FlowFiles that would have been used to created the bundle will be transferred to failure</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>The FlowFile containing the merged content</description><name>merged</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The FlowFiles that were used to create the bundle</description><name>original</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.MergeContent</type></processors><processors><id>982e1911-6be4-449b-b7ad-60da242ee355</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>-110.79999648814115</x><y>181.37032931804072</y></position><config><bulletinLevel>ERROR</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>4</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Destination</key><value><allowableValues><displayName>flowfile-content</displayName><value>flowfile-content</value></allowableValues><allowableValues><displayName>flowfile-attribute</displayName><value>flowfile-attribute</value></allowableValues><defaultValue>flowfile-content</defaultValue><description>Indicates whether the results of the JsonPath evaluation are written to the FlowFile content or a FlowFile attribute; if using attribute, must specify the Attribute Name property. If set to flowfile-content, only one JsonPath may be specified, and the property name is ignored.</description><displayName>Destination</displayName><dynamic>false</dynamic><name>Destination</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Return Type</key><value><allowableValues><displayName>auto-detect</displayName><value>auto-detect</value></allowableValues><allowableValues><displayName>json</displayName><value>json</value></allowableValues><allowableValues><displayName>scalar</displayName><value>scalar</value></allowableValues><defaultValue>auto-detect</defaultValue><description>Indicates the desired return type of the JSON Path expressions.  Selecting 'auto-detect' will set the return type to 'json' for a Destination of 'flowfile-content', and 'scalar' for a Destination of 'flowfile-attribute'.</description><displayName>Return Type</displayName><dynamic>false</dynamic><name>Return Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Path Not Found Behavior</key><value><allowableValues><displayName>warn</displayName><value>warn</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><defaultValue>ignore</defaultValue><description>Indicates how to handle missing JSON path expressions when destination is set to 'flowfile-attribute'. Selecting 'warn' will generate a warning when a JSON path expression is not found.</description><displayName>Path Not Found Behavior</displayName><dynamic>false</dynamic><name>Path Not Found Behavior</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Null Value Representation</key><value><allowableValues><displayName>the string 'null'</displayName><value>the string 'null'</value></allowableValues><allowableValues><displayName>empty string</displayName><value>empty string</value></allowableValues><defaultValue>empty string</defaultValue><description>Indicates the desired representation of JSON Path expressions resulting in a null value.</description><displayName>Null Value Representation</displayName><dynamic>false</dynamic><name>Null Value Representation</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>language</key><value><description></description><displayName>language</displayName><dynamic>true</dynamic><name>language</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>twitter.handle</key><value><description></description><displayName>twitter.handle</displayName><dynamic>true</dynamic><name>twitter.handle</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>twitter.hashtags</key><value><description></description><displayName>twitter.hashtags</displayName><dynamic>true</dynamic><name>twitter.hashtags</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>twitter.msg</key><value><description></description><displayName>twitter.msg</displayName><dynamic>true</dynamic><name>twitter.msg</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>twitter.time</key><value><description></description><displayName>twitter.time</displayName><dynamic>true</dynamic><name>twitter.time</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>twitter.tweet_id</key><value><description></description><displayName>twitter.tweet_id</displayName><dynamic>true</dynamic><name>twitter.tweet_id</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>twitter.unixtime</key><value><description></description><displayName>twitter.unixtime</displayName><dynamic>true</dynamic><name>twitter.unixtime</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>twitter.user</key><value><description></description><displayName>twitter.user</displayName><dynamic>true</dynamic><name>twitter.user</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Destination</key><value>flowfile-attribute</value></entry><entry><key>Return Type</key><value>auto-detect</value></entry><entry><key>Path Not Found Behavior</key><value>ignore</value></entry><entry><key>Null Value Representation</key><value>empty string</value></entry><entry><key>language</key><value>$.lang</value></entry><entry><key>twitter.handle</key><value>$.user.screen_name</value></entry><entry><key>twitter.hashtags</key><value>$.entities.hashtags[0].text</value></entry><entry><key>twitter.msg</key><value>$.text</value></entry><entry><key>twitter.time</key><value>$.created_at</value></entry><entry><key>twitter.tweet_id</key><value>$.id</value></entry><entry><key>twitter.unixtime</key><value>$.timestamp_ms</value></entry><entry><key>twitter.user</key><value>$.user.name</value></entry></properties><runDurationMillis>25</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Pull Key Attributes</name><relationships><autoTerminate>true</autoTerminate><description>FlowFiles are routed to this relationship when the JsonPath cannot be evaluated against the content of the FlowFile; for instance, if the FlowFile is not valid JSON</description><name>failure</name></relationships><relationships><autoTerminate>false</autoTerminate><description>FlowFiles are routed to this relationship when the JsonPath is successfully evaluated and the FlowFile is modified as a result</description><name>matched</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles are routed to this relationship when the JsonPath does not match the content of the FlowFile and the Destination is set to flowfile-content</description><name>unmatched</name></relationships><state>RUNNING</state><style/><supportsEventDriven>true</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.EvaluateJsonPath</type></processors><processors><id>3af7b6de-13bd-40c7-a177-223107fe329b</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>966.1673094034688</x><y>479.1860631043438</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Hadoop Configuration Resources</key><value><description>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</description><displayName>Hadoop Configuration Resources</displayName><dynamic>false</dynamic><name>Hadoop Configuration Resources</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Principal</key><value><description>Kerberos principal to authenticate as. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Principal</displayName><dynamic>false</dynamic><name>Kerberos Principal</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Keytab</key><value><description>Kerberos keytab associated with the principal. Requires nifi.kerberos.krb5.file to be set in your nifi.properties</description><displayName>Kerberos Keytab</displayName><dynamic>false</dynamic><name>Kerberos Keytab</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Kerberos Relogin Period</key><value><defaultValue>4 hours</defaultValue><description>Period of time which should pass before attempting a kerberos relogin</description><displayName>Kerberos Relogin Period</displayName><dynamic>false</dynamic><name>Kerberos Relogin Period</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Directory</key><value><description>The parent HDFS directory to which files should be written</description><displayName>Directory</displayName><dynamic>false</dynamic><name>Directory</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Conflict Resolution Strategy</key><value><allowableValues><displayName>replace</displayName><value>replace</value></allowableValues><allowableValues><displayName>ignore</displayName><value>ignore</value></allowableValues><allowableValues><displayName>fail</displayName><value>fail</value></allowableValues><defaultValue>fail</defaultValue><description>Indicates what should happen when a file with the same name already exists in the output directory</description><displayName>Conflict Resolution Strategy</displayName><dynamic>false</dynamic><name>Conflict Resolution Strategy</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Block Size</key><value><description>Size of each block as written to HDFS. This overrides the Hadoop Configuration</description><displayName>Block Size</displayName><dynamic>false</dynamic><name>Block Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>IO Buffer Size</key><value><description>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</description><displayName>IO Buffer Size</displayName><dynamic>false</dynamic><name>IO Buffer Size</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Replication</key><value><description>Number of times that HDFS will replicate each file. This overrides the Hadoop Configuration</description><displayName>Replication</displayName><dynamic>false</dynamic><name>Replication</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Permissions umask</key><value><description>A umask represented as an octal number which determines the permissions of files written to HDFS. This overrides the Hadoop Configuration dfs.umaskmode</description><displayName>Permissions umask</displayName><dynamic>false</dynamic><name>Permissions umask</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Owner</key><value><description>Changes the owner of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change owner</description><displayName>Remote Owner</displayName><dynamic>false</dynamic><name>Remote Owner</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Remote Group</key><value><description>Changes the group of the HDFS file to this value after it is written. This only works if NiFi is running as a user that has HDFS super user privilege to change group</description><displayName>Remote Group</displayName><dynamic>false</dynamic><name>Remote Group</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Compression codec</key><value><allowableValues><displayName>NONE</displayName><value>NONE</value></allowableValues><allowableValues><displayName>DEFAULT</displayName><value>DEFAULT</value></allowableValues><allowableValues><displayName>BZIP</displayName><value>BZIP</value></allowableValues><allowableValues><displayName>GZIP</displayName><value>GZIP</value></allowableValues><allowableValues><displayName>LZ4</displayName><value>LZ4</value></allowableValues><allowableValues><displayName>SNAPPY</displayName><value>SNAPPY</value></allowableValues><allowableValues><displayName>AUTOMATIC</displayName><value>AUTOMATIC</value></allowableValues><defaultValue>NONE</defaultValue><description></description><displayName>Compression codec</displayName><dynamic>false</dynamic><name>Compression codec</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Hadoop Configuration Resources</key><value>/etc/hadoop/conf/core-site.xml</value></entry><entry><key>Kerberos Principal</key></entry><entry><key>Kerberos Keytab</key></entry><entry><key>Kerberos Relogin Period</key></entry><entry><key>Directory</key><value>/tmp/tweets_staging</value></entry><entry><key>Conflict Resolution Strategy</key><value>replace</value></entry><entry><key>Block Size</key></entry><entry><key>IO Buffer Size</key></entry><entry><key>Replication</key><value>1</value></entry><entry><key>Permissions umask</key></entry><entry><key>Remote Owner</key></entry><entry><key>Remote Group</key></entry><entry><key>Compression codec</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutHDFS</name><relationships><autoTerminate>false</autoTerminate><description>Files that could not be written to HDFS for some reason are transferred to this relationship</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>Files that have been successfully written to HDFS are transferred to this relationship</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.hadoop.PutHDFS</type></processors><processors><id>765aa19b-a0b6-49a5-b06f-eb924b52459c</id><parentGroupId>4a8a028b-7498-4043-aa01-ddbc2b0a41cb</parentGroupId><position><x>467.54397601551534</x><y>126.61621687404391</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Solr Type</key><value><allowableValues><description>A SolrCloud instance.</description><displayName>Cloud</displayName><value>Cloud</value></allowableValues><allowableValues><description>A stand-alone Solr instance.</description><displayName>Standard</displayName><value>Standard</value></allowableValues><defaultValue>Standard</defaultValue><description>The type of Solr instance, Cloud or Standard.</description><displayName>Solr Type</displayName><dynamic>false</dynamic><name>Solr Type</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Solr Location</key><value><description>The Solr url for a Solr Type of Standard (ex: http://localhost:8984/solr/gettingstarted), or the ZooKeeper hosts for a Solr Type of Cloud (ex: localhost:9983).</description><displayName>Solr Location</displayName><dynamic>false</dynamic><name>Solr Location</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Collection</key><value><description>The Solr collection name, only used with a Solr Type of Cloud</description><displayName>Collection</displayName><dynamic>false</dynamic><name>Collection</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Content Stream Path</key><value><defaultValue>/update/json/docs</defaultValue><description>The path in Solr to post the ContentStream</description><displayName>Content Stream Path</displayName><dynamic>false</dynamic><name>Content Stream Path</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Content-Type</key><value><defaultValue>application/json</defaultValue><description>Content-Type being sent to Solr</description><displayName>Content-Type</displayName><dynamic>false</dynamic><name>Content-Type</name><required>true</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>Commit Within</key><value><description>The number of milliseconds before the given update is committed</description><displayName>Commit Within</displayName><dynamic>false</dynamic><name>Commit Within</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.1</key><value><description>Specifies the value to send for the 'f.1' request parameter</description><displayName>f.1</displayName><dynamic>true</dynamic><name>f.1</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.10</key><value><description>Specifies the value to send for the 'f.10' request parameter</description><displayName>f.10</displayName><dynamic>true</dynamic><name>f.10</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.11</key><value><description>Specifies the value to send for the 'f.11' request parameter</description><displayName>f.11</displayName><dynamic>true</dynamic><name>f.11</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.2</key><value><description>Specifies the value to send for the 'f.2' request parameter</description><displayName>f.2</displayName><dynamic>true</dynamic><name>f.2</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.3</key><value><description>Specifies the value to send for the 'f.3' request parameter</description><displayName>f.3</displayName><dynamic>true</dynamic><name>f.3</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.4</key><value><description>Specifies the value to send for the 'f.4' request parameter</description><displayName>f.4</displayName><dynamic>true</dynamic><name>f.4</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.5</key><value><description>Specifies the value to send for the 'f.5' request parameter</description><displayName>f.5</displayName><dynamic>true</dynamic><name>f.5</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.6</key><value><description>Specifies the value to send for the 'f.6' request parameter</description><displayName>f.6</displayName><dynamic>true</dynamic><name>f.6</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.7</key><value><description>Specifies the value to send for the 'f.7' request parameter</description><displayName>f.7</displayName><dynamic>true</dynamic><name>f.7</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.8</key><value><description>Specifies the value to send for the 'f.8' request parameter</description><displayName>f.8</displayName><dynamic>true</dynamic><name>f.8</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>f.9</key><value><description>Specifies the value to send for the 'f.9' request parameter</description><displayName>f.9</displayName><dynamic>true</dynamic><name>f.9</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry><entry><key>split</key><value><description>Specifies the value to send for the 'split' request parameter</description><displayName>split</displayName><dynamic>true</dynamic><name>split</name><required>false</required><sensitive>false</sensitive><supportsEl>true</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Solr Type</key><value>Cloud</value></entry><entry><key>Solr Location</key><value>localhost:2181</value></entry><entry><key>Collection</key><value>tweets</value></entry><entry><key>Content Stream Path</key><value>/update/json/docs</value></entry><entry><key>Content-Type</key><value>application/json</value></entry><entry><key>Commit Within</key><value>1000</value></entry><entry><key>f.1</key><value>id:/id</value></entry><entry><key>f.10</key><value>coordinates_s:/coordinates</value></entry><entry><key>f.11</key><value>place_s:/place</value></entry><entry><key>f.2</key><value>text_t:/text</value></entry><entry><key>f.3</key><value>screenName_s:/user/screen_name</value></entry><entry><key>f.4</key><value>language_s:/lang</value></entry><entry><key>f.5</key><value>twitter_created_at_dt:/created_at</value></entry><entry><key>f.6</key><value>tag_ss:/entities/hashtags</value></entry><entry><key>f.7</key><value>originalposter_s:/retweeted_status/user/screen_name</value></entry><entry><key>f.8</key><value>source_s:/source</value></entry><entry><key>f.9</key><value>geo_s:/geo</value></entry><entry><key>split</key><value>/</value></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>0 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>PutSolrContentStream</name><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that failed because Solr is unreachable</description><name>connection_failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>FlowFiles that failed for any reason other than Solr being unreachable</description><name>failure</name></relationships><relationships><autoTerminate>true</autoTerminate><description>The original FlowFile</description><name>success</name></relationships><state>RUNNING</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.solr.PutSolrContentStream</type></processors></contents><disabledCount>0</disabledCount><inactiveRemotePortCount>0</inactiveRemotePortCount><inputPortCount>0</inputPortCount><invalidCount>0</invalidCount><name>Twitter Dashboard - Push tweets into HDFS/Solr</name><outputPortCount>0</outputPortCount><parent><id>7c84501d-d10c-407c-b9f3-1d80e38fe36a</id><name>NiFi Flow</name></parent><runningCount>7</runningCount><stoppedCount>1</stoppedCount></processGroups><processors><id>7f905184-2476-486a-b9b7-566bda1df7d1</id><parentGroupId>7c84501d-d10c-407c-b9f3-1d80e38fe36a</parentGroupId><position><x>157.0297455184883</x><y>165.29097709850336</y></position><config><bulletinLevel>WARN</bulletinLevel><comments></comments><concurrentlySchedulableTaskCount>1</concurrentlySchedulableTaskCount><defaultConcurrentTasks><entry><key>TIMER_DRIVEN</key><value>1</value></entry><entry><key>EVENT_DRIVEN</key><value>0</value></entry><entry><key>CRON_DRIVEN</key><value>1</value></entry></defaultConcurrentTasks><defaultSchedulingPeriod><entry><key>TIMER_DRIVEN</key><value>0 sec</value></entry><entry><key>CRON_DRIVEN</key><value>* * * * * ?</value></entry></defaultSchedulingPeriod><descriptors><entry><key>Command</key><value><description>Specifies the command to be executed; if just the name of an executable is provided, it must be in the user's environment PATH.</description><displayName>Command</displayName><dynamic>false</dynamic><name>Command</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Command Arguments</key><value><description>The arguments to supply to the executable delimited by white space. White space can be escaped by enclosing it in double-quotes.</description><displayName>Command Arguments</displayName><dynamic>false</dynamic><name>Command Arguments</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Batch Duration</key><value><description>If the process is expected to be long-running and produce textual output, a batch duration can be specified so that the output will be captured for this amount of time and a FlowFile will then be sent out with the results and a new FlowFile will be started, rather than waiting for the process to finish before sending out the results</description><displayName>Batch Duration</displayName><dynamic>false</dynamic><name>Batch Duration</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Redirect Error Stream</key><value><allowableValues><displayName>true</displayName><value>true</value></allowableValues><allowableValues><displayName>false</displayName><value>false</value></allowableValues><defaultValue>false</defaultValue><description>If true will redirect any error stream output of the process to the output stream. This is particularly helpful for processes which write extensively to the error stream or for troubleshooting.</description><displayName>Redirect Error Stream</displayName><dynamic>false</dynamic><name>Redirect Error Stream</name><required>false</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry><entry><key>Argument Delimiter</key><value><defaultValue> </defaultValue><description>Delimiter to use to separate arguments for a command [default: space]. Must be a single character.</description><displayName>Argument Delimiter</displayName><dynamic>false</dynamic><name>Argument Delimiter</name><required>true</required><sensitive>false</sensitive><supportsEl>false</supportsEl></value></entry></descriptors><lossTolerant>false</lossTolerant><penaltyDuration>30 sec</penaltyDuration><properties><entry><key>Command</key><value>sqoop</value></entry><entry><key>Command Arguments</key><value>job -exec factsales</value></entry><entry><key>Batch Duration</key></entry><entry><key>Redirect Error Stream</key></entry><entry><key>Argument Delimiter</key></entry></properties><runDurationMillis>0</runDurationMillis><schedulingPeriod>300 sec</schedulingPeriod><schedulingStrategy>TIMER_DRIVEN</schedulingStrategy><yieldDuration>1 sec</yieldDuration></config><name>Sample to schedule Sqoop job</name><relationships><autoTerminate>true</autoTerminate><description>All created FlowFiles are routed to this relationship</description><name>success</name></relationships><state>STOPPED</state><style/><supportsEventDriven>false</supportsEventDriven><supportsParallelProcessing>true</supportsParallelProcessing><type>org.apache.nifi.processors.standard.ExecuteProcess</type></processors></snippet><timestamp>01/14/2016 03:48:02 UTC</timestamp></template>